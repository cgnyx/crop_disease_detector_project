{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238993cf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T03:19:42.496328Z",
     "iopub.status.busy": "2025-05-29T03:19:42.496069Z",
     "iopub.status.idle": "2025-05-29T03:20:00.186569Z",
     "shell.execute_reply": "2025-05-29T03:20:00.185750Z"
    },
    "papermill": {
     "duration": 17.695422,
     "end_time": "2025-05-29T03:20:00.187988",
     "exception": false,
     "start_time": "2025-05-29T03:19:42.492566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- Configuration ---\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 30 \n",
    "DATASET_PATH = '/kaggle/input/plantvillage-dataset/color' \n",
    "\n",
    "MODEL_EXPORT_BASE_PATH = '/kaggle/working/models/plant_disease_detector'\n",
    "MODEL_VERSION = 1\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Is GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ade39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:20:00.199017Z",
     "iopub.status.busy": "2025-05-29T03:20:00.198579Z",
     "iopub.status.idle": "2025-05-29T03:20:00.211173Z",
     "shell.execute_reply": "2025-05-29T03:20:00.210615Z"
    },
    "papermill": {
     "duration": 0.016828,
     "end_time": "2025-05-29T03:20:00.212147",
     "exception": false,
     "start_time": "2025-05-29T03:20:00.195319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading and Preprocessing Function\n",
    "def load_and_preprocess_data(dataset_path):\n",
    "    # This will list folders like 'Apple___Apple_scab', 'Tomato___Early_blight'\n",
    "    combined_disease_folders = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "\n",
    "    # Extract unique crop names from the folder names\n",
    "    crop_types = sorted(list(set([folder.split('___')[0] for folder in combined_disease_folders])))\n",
    "    crop_name_to_index = {name: i for i, name in enumerate(crop_types)}\n",
    "    num_crop_types = len(crop_types)\n",
    "\n",
    "    # The full disease labels will be the combined folder names themselves\n",
    "    disease_labels = sorted(combined_disease_folders)\n",
    "    full_disease_name_to_index = {name: i for i, name in enumerate(disease_labels)}\n",
    "    num_disease_classes = len(disease_labels)\n",
    "\n",
    "    # Collect all image paths and their corresponding labels\n",
    "    all_image_paths = []\n",
    "    all_labels_disease = []\n",
    "    all_labels_crop_type = []\n",
    "\n",
    "    print(f\"Found {len(combined_disease_folders)} combined disease folders.\")\n",
    "    for combined_folder_name in combined_disease_folders:\n",
    "        combined_folder_path = os.path.join(dataset_path, combined_folder_name)\n",
    "        crop_name = combined_folder_name.split('___')[0]\n",
    "\n",
    "        for img_name in os.listdir(combined_folder_path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                all_image_paths.append(os.path.join(combined_folder_path, img_name))\n",
    "                all_labels_disease.append(full_disease_name_to_index[combined_folder_name])\n",
    "                all_labels_crop_type.append(crop_name_to_index[crop_name])\n",
    "\n",
    "    print(f\"Total images loaded: {len(all_image_paths)}\")\n",
    "\n",
    "    all_labels_disease = np.array(all_labels_disease)\n",
    "    all_labels_crop_type = np.array(all_labels_crop_type)\n",
    "\n",
    "    X_train_paths, X_val_paths, y_train_disease, y_val_disease, y_train_crop, y_val_crop = train_test_split(\n",
    "        all_image_paths, all_labels_disease, all_labels_crop_type,\n",
    "        test_size=0.2, random_state=42, stratify=all_labels_disease\n",
    "    )\n",
    "\n",
    "    def data_generator(image_paths, disease_labels_indices, crop_type_labels_indices, is_training=True):\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255, # Normalize pixel values to 0-1\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        ) if is_training else ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        num_samples = len(image_paths)\n",
    "        while True:\n",
    "            indices = np.arange(num_samples)\n",
    "            if is_training:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            for i in range(0, num_samples, BATCH_SIZE):\n",
    "                batch_indices = indices[i:i + BATCH_SIZE]\n",
    "                \n",
    "                batch_image_paths = [image_paths[j] for j in batch_indices]\n",
    "                batch_disease_labels = disease_labels_indices[batch_indices]\n",
    "                batch_crop_type_labels = crop_type_labels_indices[batch_indices]\n",
    "\n",
    "                images = []\n",
    "                for img_path in batch_image_paths:\n",
    "                    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    images.append(img)\n",
    "                \n",
    "                images = np.array(images)\n",
    "                \n",
    "                if is_training:\n",
    "                    # --- FIX IS HERE ---\n",
    "                    # Replace .next() with .__next__() for newer TensorFlow versions\n",
    "                    images = datagen.flow(images, batch_size=len(images), shuffle=False).__next__()\n",
    "                else:\n",
    "                    images = images / 255.0 # Manual rescale for validation without flow\n",
    "\n",
    "                disease_one_hot = tf.keras.utils.to_categorical(batch_disease_labels, num_classes=len(disease_labels))\n",
    "                crop_type_input_for_batch = np.array(batch_crop_type_labels)\n",
    "\n",
    "                yield {\"image_input\": images, \"crop_type_input\": crop_type_input_for_batch}, disease_one_hot\n",
    "\n",
    "    train_generator = data_generator(X_train_paths, y_train_disease, y_train_crop, is_training=True)\n",
    "    val_generator = data_generator(X_val_paths, y_val_disease, y_val_crop, is_training=False)\n",
    "\n",
    "    return train_generator, val_generator, \\\n",
    "           len(X_train_paths), len(X_val_paths), \\\n",
    "           num_crop_types, num_disease_classes, \\\n",
    "           crop_name_to_index, disease_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c04a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:20:00.217135Z",
     "iopub.status.busy": "2025-05-29T03:20:00.216751Z",
     "iopub.status.idle": "2025-05-29T03:20:00.221971Z",
     "shell.execute_reply": "2025-05-29T03:20:00.221442Z"
    },
    "papermill": {
     "duration": 0.008749,
     "end_time": "2025-05-29T03:20:00.222937",
     "exception": false,
     "start_time": "2025-05-29T03:20:00.214188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Build Model Function\n",
    "def build_model(num_crop_types, num_disease_classes):\n",
    "    image_input = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name='image_input')\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "    base_model.trainable = False # Freeze base model initially\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    crop_type_input = Input(shape=(1,), name='crop_type_input', dtype='int32')\n",
    "    y = tf.keras.layers.Embedding(input_dim=num_crop_types, output_dim=10)(crop_type_input)\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    combined = concatenate([x, y])\n",
    "\n",
    "    z = Dense(128, activation='relu')(combined)\n",
    "    z = Dropout(0.3)(z)\n",
    "    output = Dense(num_disease_classes, activation='softmax', name='predictions')(z)\n",
    "\n",
    "    model = Model(inputs=[image_input, crop_type_input], outputs=output)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8aece1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:20:00.227733Z",
     "iopub.status.busy": "2025-05-29T03:20:00.227552Z",
     "iopub.status.idle": "2025-05-29T03:20:06.190816Z",
     "shell.execute_reply": "2025-05-29T03:20:06.190036Z"
    },
    "papermill": {
     "duration": 5.967203,
     "end_time": "2025-05-29T03:20:06.192190",
     "exception": false,
     "start_time": "2025-05-29T03:20:00.224987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Execute Data Loading and Get Mappings\n",
    "print(\"Loading and preparing data...\")\n",
    "train_generator, val_generator, \\\n",
    "train_samples, val_samples, \\\n",
    "num_crop_types, num_disease_classes, \\\n",
    "crop_name_to_index, disease_labels = load_and_preprocess_data(DATASET_PATH)\n",
    "\n",
    "print(f\"\\nDetected {num_crop_types} crop types and {num_disease_classes} total disease classes.\")\n",
    "print(\"Crop Name to Index Mapping:\")\n",
    "for crop_name, index in crop_name_to_index.items():\n",
    "    print(f\"  {crop_name}: {index}\")\n",
    "print(\"\\nDisease Labels (full list):\")\n",
    "for i, label in enumerate(disease_labels):\n",
    "    print(f\"  {i}: {label}\")\n",
    "\n",
    "steps_per_epoch_train = train_samples // BATCH_SIZE\n",
    "if train_samples % BATCH_SIZE != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "\n",
    "steps_per_epoch_val = val_samples // BATCH_SIZE\n",
    "if val_samples % BATCH_SIZE != 0:\n",
    "    steps_per_epoch_val += 1\n",
    "\n",
    "# Save mapping files\n",
    "with open('crop_name_to_index.txt', 'w') as f:\n",
    "    for name, idx in crop_name_to_index.items():\n",
    "        f.write(f\"{name}:{idx}\\n\")\n",
    "with open('disease_labels.txt', 'w') as f:\n",
    "    for label in disease_labels:\n",
    "        f.write(f\"{label}\\n\")\n",
    "print(\"\\nMapping files (crop_name_to_index.txt, disease_labels.txt) saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5040fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:20:06.197993Z",
     "iopub.status.busy": "2025-05-29T03:20:06.197739Z",
     "iopub.status.idle": "2025-05-29T03:20:11.335556Z",
     "shell.execute_reply": "2025-05-29T03:20:11.334785Z"
    },
    "papermill": {
     "duration": 5.158313,
     "end_time": "2025-05-29T03:20:11.353077",
     "exception": false,
     "start_time": "2025-05-29T03:20:06.194764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Build and Summarize Model\n",
    "print(\"\\nBuilding model...\")\n",
    "model, base_model = build_model(num_crop_types, num_disease_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3268b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:20:11.374036Z",
     "iopub.status.busy": "2025-05-29T03:20:11.373523Z",
     "iopub.status.idle": "2025-05-29T05:01:46.681404Z",
     "shell.execute_reply": "2025-05-29T05:01:46.680370Z"
    },
    "papermill": {
     "duration": 6095.331319,
     "end_time": "2025-05-29T05:01:46.694231",
     "exception": false,
     "start_time": "2025-05-29T03:20:11.362912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Initial Training (Feature Extraction)\n",
    "print(\"\\nStarting Phase 1: Feature Extraction (Training top layers)...\")\n",
    "\n",
    "# Define Early Stopping callback\n",
    "early_stopping_phase1 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3, # Can be 3-5\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model (if not already compiled or re-compiling for clarity)\n",
    "# Ensure base_model.trainable is False before this compilation\n",
    "# (It's already set to False in build_model function)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train Phase 1\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=15, # Give it enough epochs to converge in Phase 1, but EarlyStopping will manage it\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    callbacks=[early_stopping_phase1]\n",
    ")\n",
    "print(\"Phase 1: Feature Extraction training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39895cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T05:01:48.289628Z",
     "iopub.status.busy": "2025-05-29T05:01:48.288644Z",
     "iopub.status.idle": "2025-05-29T06:33:54.179161Z",
     "shell.execute_reply": "2025-05-29T06:33:54.178334Z"
    },
    "papermill": {
     "duration": 5527.816491,
     "end_time": "2025-05-29T06:33:55.277761",
     "exception": false,
     "start_time": "2025-05-29T05:01:47.461270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NEW Cell 7: Fine-Tuning Phase\n",
    "print(\"\\nStarting Phase 2: Fine-Tuning (Unfreezing and training parts of base model)...\")\n",
    "\n",
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Optionally, unfreeze only a subset of layers (e.g., the last few convolutional blocks)\n",
    "# This can prevent catastrophic forgetting of learned features.\n",
    "# MobileNetV2 has ~155 layers including input/batchnorm.\n",
    "# You might unfreeze layers from a certain index onwards, or a percentage from the end.\n",
    "# For example, unfreeze the last ~20-30% of MobileNetV2 layers.\n",
    "# Let's say we keep the first 100 layers frozen and unfreeze the rest.\n",
    "# You might need to experiment with the 'unfreeze_from_layer' value.\n",
    "UNFREEZE_FROM_LAYER = 250 # Adjust this value based on experimentation for ResNet101\n",
    "for layer in base_model.layers[:UNFREEZE_FROM_LAYER]:\n",
    "    layer.trainable = False\n",
    "print(f\"Number of trainable layers in base model after unfreezing: {len([layer for layer in base_model.trainable_variables])}\")\n",
    "\n",
    "\n",
    "# Compile the model with a much lower learning rate for fine-tuning\n",
    "# This is CRUCIAL to prevent overwriting useful pre-trained features\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # A very small learning rate (e.g., 0.00001)\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define Early Stopping callback for fine-tuning\n",
    "early_stopping_phase2 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5, # Give it more patience for fine-tuning, as improvements can be subtle\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Phase 2 (fine-tuning)\n",
    "# You can set EPOCHS_FINE_TUNE higher, as EarlyStopping will manage it\n",
    "EPOCHS_FINE_TUNE = 30 \n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    callbacks=[early_stopping_phase2]\n",
    ")\n",
    "print(\"Phase 2: Fine-Tuning training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c5226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:33:58.301206Z",
     "iopub.status.busy": "2025-05-29T06:33:58.300917Z",
     "iopub.status.idle": "2025-05-29T06:33:58.720196Z",
     "shell.execute_reply": "2025-05-29T06:33:58.719567Z"
    },
    "papermill": {
     "duration": 1.933342,
     "end_time": "2025-05-29T06:33:58.721959",
     "exception": false,
     "start_time": "2025-05-29T06:33:56.788617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Visualize Training History\n",
    "# Combine history objects for plotting\n",
    "acc = history_phase1.history['accuracy'] + history_phase2.history['accuracy']\n",
    "val_acc = history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy']\n",
    "\n",
    "loss = history_phase1.history['loss'] + history_phase2.history['loss']\n",
    "val_loss = history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy (Combined Phases)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss (Combined Phases)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9306441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:34:01.676369Z",
     "iopub.status.busy": "2025-05-29T06:34:01.676079Z",
     "iopub.status.idle": "2025-05-29T06:34:56.982885Z",
     "shell.execute_reply": "2025-05-29T06:34:56.980054Z"
    },
    "papermill": {
     "duration": 58.333926,
     "end_time": "2025-05-29T06:34:58.495526",
     "exception": false,
     "start_time": "2025-05-29T06:34:00.161600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 9: Save Model for TensorFlow Serving\n",
    "export_path = os.path.join(MODEL_EXPORT_BASE_PATH, str(MODEL_VERSION))\n",
    "\n",
    "if os.path.exists(export_path):\n",
    "    print(f\"Removing existing model version at {export_path}\")\n",
    "    shutil.rmtree(export_path)\n",
    "\n",
    "tf.saved_model.save(model, export_path)\n",
    "\n",
    "print(f\"Model saved to: {export_path}\")\n",
    "\n",
    "# To easily download the model folder and mapping files from Kaggle's \"Output\" tab\n",
    "# You need to ensure they are written to /kaggle/working/\n",
    "# The .txt files are already saved there.\n",
    "# We can zip the model directory for easier download.\n",
    "\n",
    "# Zip the model folder\n",
    "model_zip_path = f\"/kaggle/working/plant_disease_detector_model_v{MODEL_VERSION}.zip\"\n",
    "shutil.make_archive(\n",
    "    base_name=os.path.join('/kaggle/working', f\"plant_disease_detector_model_v{MODEL_VERSION}\"),\n",
    "    format='zip',\n",
    "    root_dir='/kaggle/working/models', # Base directory to start archiving from\n",
    "    base_dir='plant_disease_detector'  # The specific directory inside root_dir to archive\n",
    ")\n",
    "print(f\"\\nModel zipped to: {model_zip_path}\")\n",
    "print(\"Now, 'Save Version' (Commit) your notebook.\")\n",
    "print(\"After the commit run completes, go to the 'Output' tab of that version.\")\n",
    "print(\"You will find 'plant_disease_detector_model_v1.zip', 'crop_name_to_index.txt', and 'disease_labels.txt' available for download.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 277323,
     "sourceId": 658267,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11725.574429,
   "end_time": "2025-05-29T06:35:03.682649",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T03:19:38.108220",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
